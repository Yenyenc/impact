# Mise en place de Metabase

## Problèmatique

On souhaite mettre à disposition de toutes les personnes de l'équipe Impact (y compris non techniques) les données métier nécessaires pour piloter l'activité du projet Impact, et en particulier suivre notre objectif d'impact pour commencer.

Metabase est l'outil choisi par la communauté betagouv pour ce type d'usage.

L'outil doit être déployé et configuré pour être alimenté par nos données de production.
On souhaite limiter les risques de sécurité et l'accès aux données potentiellement sensibles (en particulier les données personnelles).


## Solutions envisagées

### 1. Connecter Metabase directement à notre base de données de production

- Solution la plus simple et rapide à mettre en place au départ.
- Accès direct aux données, pas d'intervention technique nécessaire lorsque les besoins BI évoluent.
- Accès en temps réel aux données (tant ques les performances le permettent).
- Forte dépendance à l'évolution des modèles métiers (toute évolution dans notre base de données peut casser les tableaux de bords créés dans Metabase).
- Les données exposées peuvent être techniques et peu compréhensibles pour les personnes non techniques.
- Problèmes de performance possibles, qui peuvent impacter la production.
- Pas très sécurisé.

### 2. Alimenter une base de données anonymisée dédiée de façon régulière via un script d'export technique (type bash)

- Plus sécurisé.
- Moins de problèmes de performance, pas d'impact sur la production.
- Accès à la plupart des données, peu d'intervention technique nécessaire lorsque les besoins BI évoluent.
- Dépendance à l'évolution des modèles métiers non contrôlée (une évolution peut casser le script d'export).
- Les données exposées sont peu facilement transformées. Elles peuvent rester techniques et peu compréhensibles pour les non développeurs.
- Peu testable.
- Pas de temps réel.

### 3. Alimenter une base de données anonymisée dédiée de façon régulière via une synchronisation depuis une nouvelle application Django métier

- Plus sécurisé.
- Moindre dépendance à l'évolution des modèles métiers. Testable.
- Les données exposées peuvent être transformées pour correspondre aux besoins exprimés/être facilement compréhensibles.
- Les données exposées peuvent facilement évoluer selon les besoins exprimés.
- Pas de temps réel.
- Problèmes de performance possibles sur la synchronisation si le nombre de données synchronisées et leur complexité augmentent trop.
- Accès restreint aux données choisies, nécessite une intervention technique lorsque le besoin BI évolue. Dosage à trouver pour donner suffisamment d'autonomie aux utilisateurs.

### 4. Alimenter une base de données anonymisée dédiée de façon continue via l'émission d'évènements (event sourcing)

- Plus sécurisé.
- Temps réel.
- Pas de problème de performance.
- Plus complexe à mettre en place au départ.
- Les données exposées sont des évènements, pas forcément compréhensibles pour les personnes non habituées.
- Accès restreint aux données choisies, nécessite une intervention technique dès que le besoin BI évolue.
- Evolution du code de production nécessaire lorsque le besoin évolue + migration ou perte des évènements passés (enrichissement a posteriori des évènements).


## Choix

Choix 3 : Alimenter une base de données anonymisée dédiée de façon régulière via une synchronisation depuis une nouvelle application Django métier (`metabase`) pour le compromis entre la sécurité, la facilité et l'évolution possible.

Dans un premier temps la base de données anonymisée est un simple schéma dans la base de données postgreSQL de Metabase pour des contraintes de déploiement sur Scalingo (nombre de containers applicatifs/bases de données disponibles restreint).
